# This file is part of James CI.
#
# James CI is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# James CI is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more
# details.
#
# You should have received a copy of the GNU Lesser General Public License along
# with James CI. If not, see <http://www.gnu.org/licenses/>.
#
#
# Copyright (C)
#   2017 Alexander Haase <ahaase@alexhaase.de>
#

import os
import time

from .job_base import JobBase
from .status import Status


class Job(JobBase):
    """
    This class helps managing jobs. It imports the job's configuration and
    handles all neccessary error checks.
    """

    def __init__(self, name, data, pipeline, with_meta=True):
        """
        :param str name: Name of this job.
        :param dict data: Dict containing the job's configuration. This will be
          an item of the `jobs` key in the configuration passed to the pipeline.
        :param Pipeline pipeline: Reference to the job's pipeline.
        :param bool with_meta: Whether to load metadata from `data`. The
          :py:class:`~.Pipeline` should pass the value passed to its
          :py:meth:`~.Pipeline.__init__` method.
        """
        # Initialize the parent class, which imports the common keys for
        # pipelines and jobs. The pipeline of this job will be used as parent
        # namespace, so the env, git and steps attributes of the pipeline will
        # be used whenever the job has no individual configurations for these
        # attributes set.
        super().__init__(parent=pipeline)
        super()._import(data)

        # Import the job-specific configurations, except meta-data, as it will
        # not be loaded in any situation.
        #
        # The data will not be converted to read-only objects to reduce the
        # overhead, as most objects will not be modified but just a single one.
        self._name = name
        self._pipeline = pipeline
        self._stage = self._load_stage(data)

        # If enabled, import the meta-data for this job from the provided data
        # dictionary. There won't be any specialized checks for the availability
        # of any of the required fields, but an exception will be thrown if a
        # key is not available.
        if with_meta:
            self._status = Status[data['meta']['status']]
            self._start = data['meta'].get('start')
            self._finish = data['meta'].get('end')

        # If no meta-data should be imported from the provided configuration,
        # initialize the meta-data with default values. The initial status of a
        # job will be 'created', start- and end-time will be None.
        else:
            self._status = Status.created
            self._start = None
            self._finish = None

    def dump(self):
        """
        Dump the configuration as dict.


        :return: The configuration of this job.
        :rtype: dict
        """
        # Get the dictionary generated by the parent class. This dictionary will
        # be updated with the job-specific configuration.
        ret = super().dump()
        ret['meta'] = {
            'status': str(self._status)
        }
        if self._start:
            ret['meta']['start'] = self._start
        if self._finish:
            ret['meta']['end'] = self._finish
        if self._stage:
            ret['stage'] = self._stage
        return ret

    def _load_stage(self, data):
        """
        Load the stage for this job from `data` and check it matches the
        pipeline's configuration.


        :param dict data: Dict containing the job's configuration. It should be
          pass-through from :py:meth:`__init__`.
        :return: The job's stage.
        :rtype: str

        :raises IndexError: The stage of this job is not defined in the
          pipeline's list of :py:attr:`~.Pipeline.stages`.
        :raises AttributeError: The job is not assigned to any stage, but the
          pipeline uses stages.
        """
        # Load the stage key from data. If no stage is defined in data, the
        # stage will default to None.
        stage = data.get('stage')

        # Check if the stage is defined in the pipeline's list of stages.
        # Otherwise this job will never run and the pipeline never finalizes.
        if stage and stage not in self._pipeline.stages:
            raise IndexError("stage '{}' not defined in pipeline".format(stage))

        # If no stage has been defined, check if the pipeline uses stages.
        # Otherwise this job will never run and the pipeline never finalizes.
        if not stage and self._pipeline.stages:
            raise AttributeError('no stage assigned to job')

        # If all checks passed, return the loaded stage.
        return stage

    def __enter__(self):
        """
        Enter the runtime context related to the job's pipeline and return a
        reference to this job in the pipeline's context.

        .. seealso::
          See the :py:meth:`~.Pipeline.__enter__` method of
          :py:class:`~.Pipeline` for further information.


        :return: The writeable job instance in the pipeline's context.
        :rtype: WriteableJob
        """
        return self._pipeline.__enter__().jobs[self._name]

    def __exit__(self, exc_type, exc_value, traceback):
        """
        Exit the runtime context related to the job's pipeline.
        """
        self._pipeline.__exit__(exc_type, exc_value, traceback)

    @property
    def finish(self):
        """
        :return: The job's finish time as UNIX timestamp.
        :rtype: None, int
        """
        return self._finish

    @property
    def logfile(self):
        """
        :return: Path of the job's logfile.
        :rtype: str
        """
        return os.path.join(self.pipeline.wd, self._name + '.txt')

    @property
    def name(self):
        """
        :return: The job's name.
        :rtype: str
        """
        return self._name

    @property
    def pipeline(self):
        """
        :return: The job's pipeline.
        :rtype: Pipeline
        """
        return self._pipeline

    @property
    def stage(self):
        """
        :return: The job's stage.
        :rtype: None, str
        """
        return self._stage

    @property
    def start(self):
        """
        :return: The job's start time as UNIX timestamp.
        :rtype: None, int
        """
        return self._start

    @property
    def status(self):
        """
        :return: The job's status.
        :rtype: Status
        """
        return self._status


class WriteableJob(Job):
    """
    By default a :py:class:`Job` is write-protected. However, some attributes of
    a job need to be changed while running the job. The :py:class:`~.Pipeline`
    class may use this class instead of :py:class:`Job` for loading jobs, so the
    job's attributes may be changed.

    .. note::
      Not all of the job's attributes will be writeable, as most attributes
      shall not be edited during runtime.
    """

    def start_job(self):
        """
        Set the job's status to :py:attr:`~.Status.running` and the start time
        to the current UNIX timestamp.
        """
        # Set the status of this job to running and the start time to the
        # current UNIX timestamp. The end time will be set to None to remove
        # previous values (e.g. if the job will be run a second time).
        self._status = Status.running
        self._start = int(time.time())
        self._finish = None

    def finish_job(self, status):
        """
        Set the job's status to `status` and the finish time to the current UNIX
        timestamp.

        .. note::
          If the job has not been started yet (e.g. because an error occured
          before :py:meth:`start_job` has been called), this method will also
          set the job's start-time to the current UNIX timestamp.
        """
        # Set the status of the job to the pased one.
        self._status = status

        # Set the job's end-time, and also the start-time if not already set, to
        # the current UNIX timestamp.
        if not self._start:
            self._start = int(time.time())
        self._finish = int(time.time())

    @Job.status.setter
    def status(self, status):
        """
        Set the job's status.

        .. note::
          For setting the status when starting and finishing a job use
          :py:meth:`start_job` and :py:meth:`end_job`.


        :param Status status: The status to be set.
        """
        self._status = status
